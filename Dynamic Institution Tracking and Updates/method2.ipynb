{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df07eb3-5c75-4125-a41a-179f8c661f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    " \n",
    "import os\n",
    "import json\n",
    " \n",
    "from openai import OpenAI\n",
    "from openai.types.chat.chat_completion import Choice\n",
    " \n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.moonshot.cn/v1\",\n",
    "    api_key=\"Sorry but we cannot show this\",\n",
    ")\n",
    " \n",
    " \n",
    "# search 工具的具体实现，这里我们只需要返回参数即可\n",
    "def search_impl(arguments: Dict[str, Any]) -> Any:\n",
    "    \"\"\"\n",
    "    在使用 Moonshot AI 提供的 search 工具的场合，只需要原封不动返回 arguments 即可，\n",
    "    不需要额外的处理逻辑。\n",
    " \n",
    "    但如果你想使用其他模型，并保留联网搜索的功能，那你只需要修改这里的实现（例如调用搜索\n",
    "    和获取网页内容等），函数签名不变，依然是 work 的。\n",
    " \n",
    "    这最大程度保证了兼容性，允许你在不同的模型间切换，并且不需要对代码有破坏性的修改。\n",
    "    \"\"\"\n",
    "    return arguments\n",
    " \n",
    " \n",
    "def chat(messages) -> Choice:\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"moonshot-v1-8k\",\n",
    "        messages=messages,\n",
    "        temperature=0.3,\n",
    "        tools=[\n",
    "            {\n",
    "                \"type\": \"builtin_function\",  # <-- 使用 builtin_function 声明 $web_search 函数，请在每次请求都完整地带上 tools 声明\n",
    "                \"function\": {\n",
    "                    \"name\": \"$web_search\",\n",
    "                },\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0]\n",
    " \n",
    " \n",
    "def single_search(university_name):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"你是月之暗面（Kimi）的智能客服，你负责回答用户提出的各种问题。你的回答需要返回一个JSON列表，里面包含了至少一个4个属性（support, type, name, email）的JSON对象。\"},\n",
    "    ]\n",
    " \n",
    "    # 初始提问\n",
    "    messages.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"问{university_name}是否有支持多邻国英语测试的留学项目？如果有，首先返回所有这些留学项目的信息，作为JSON列表中的每一个对象；对于每一个留学项目，support返回Y，同时根据类型设置type的值（本科生项目：UG，研究生项目：PG，暑研或者交换学期：EX），否则返回support:N，且type为NI；将找到的项目名称返回为name（name统一返回英文），并且尽可能返回其项目的联系邮箱为email，联系邮箱请认真甄别，邮箱是非常重要的信息！\"\n",
    "    })\n",
    " \n",
    "    finish_reason = None\n",
    "    while finish_reason is None or finish_reason == \"tool_calls\":\n",
    "        choice = chat(messages)\n",
    "        finish_reason = choice.finish_reason\n",
    "        print(finish_reason, choice)\n",
    "        if finish_reason == \"tool_calls\":  # <-- 判断当前返回内容是否包含 tool_calls\n",
    "            messages.append(choice.message)  # <-- 我们将 Kimi 大模型返回给我们的 assistant 消息也添加到上下文中，以便于下次请求时 Kimi 大模型能理解我们的诉求\n",
    "            for tool_call in choice.message.tool_calls:  # <-- tool_calls 可能是多个，因此我们使用循环逐个执行\n",
    "                tool_call_name = tool_call.function.name\n",
    "                tool_call_arguments = json.loads(tool_call.function.arguments)  # <-- arguments 是序列化后的 JSON Object，我们需要使用 json.loads 反序列化一下\n",
    "                if tool_call_name == \"$web_search\":\n",
    "                    tool_result = search_impl(tool_call_arguments)\n",
    "                else:\n",
    "                    tool_result = f\"Error: unable to find tool by name '{tool_call_name}'\"\n",
    " \n",
    "                # 使用函数执行结果构造一个 role=tool 的 message，以此来向模型展示工具调用的结果；\n",
    "                # 注意，我们需要在 message 中提供 tool_call_id 和 name 字段，以便 Kimi 大模型\n",
    "                # 能正确匹配到对应的 tool_call。\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"name\": tool_call_name,\n",
    "                    \"content\": json.dumps(tool_result),  # <-- 我们约定使用字符串格式向 Kimi 大模型提交工具调用结果，因此在这里使用 json.dumps 将执行结果序列化成字符串\n",
    "                })\n",
    "        print(choice.message.tool_calls)\n",
    " \n",
    "    return choice.message.content  # <-- 在这里，我们才将模型生成的回复返回给用户"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "05247322-e704-4332-8ff8-f86db4414f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "文件内容的前5行:\n",
      "                                                   name  \\\n",
      "0                   Engineering Institute of Technology   \n",
      "1                        Atharva College of Engineering   \n",
      "2                                    West Herts College   \n",
      "3             Bhagwan Parshuram Institute of Technology   \n",
      "4                   Royal Holloway University of London   \n",
      "...                                                 ...   \n",
      "3285        City St George's, University of London (II)   \n",
      "3286  City St George's, University of London (School...   \n",
      "3287                            Trinity College Bristol   \n",
      "3288                            Trinity College Bristol   \n",
      "3289                     California College of the Arts   \n",
      "\n",
      "                                             domains  \\\n",
      "0                             ['student.eit.edu.au']   \n",
      "1                               ['atharvacoe.ac.in']   \n",
      "2     ['student.westherts.ac.uk', 'westherts.ac.uk']   \n",
      "3               ['bpitindia.edu.in', 'bpitindia.in']   \n",
      "4                                     ['rhul.ac.uk']   \n",
      "...                                              ...   \n",
      "3285                        ['student.staffs.ac.uk']   \n",
      "3286                                  ['sgul.ac.uk']   \n",
      "3287                 ['trinitycollegebristol.ac.uk']   \n",
      "3288                 ['trinitycollegebristol.ac.uk']   \n",
      "3289                                     ['cca.edu']   \n",
      "\n",
      "                                         web_pages         country  \\\n",
      "0                      ['https://www.eit.edu.au/']       Australia   \n",
      "1                     ['https://atharvacoe.ac.in']           India   \n",
      "2                      ['https://westherts.ac.uk']  United Kingdom   \n",
      "3                       ['http://bpitindia.ac.in']           India   \n",
      "4                           ['https://rhul.ac.uk']  United Kingdom   \n",
      "...                                            ...             ...   \n",
      "3285          ['https://www.citystgeorges.ac.uk/']  United Kingdom   \n",
      "3286                   ['https://www.sgul.ac.uk/']  United Kingdom   \n",
      "3287  ['https://www.trinitycollegebristol.ac.uk/']  United Kingdom   \n",
      "3288  ['https://www.trinitycollegebristol.ac.uk/']  United Kingdom   \n",
      "3289                          ['https://cca.edu/']   United States   \n",
      "\n",
      "     alpha_two_code  stateprovince  \n",
      "0                AU            NaN  \n",
      "1                IN         Mumbai  \n",
      "2                GB            NaN  \n",
      "3                IN          Delhi  \n",
      "4                GB            NaN  \n",
      "...             ...            ...  \n",
      "3285             GB         London  \n",
      "3286             GB         London  \n",
      "3287             GB        Bristol  \n",
      "3288             GB        Bristol  \n",
      "3289             US  San Francisco  \n",
      "\n",
      "[3290 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "csv_file = \"the_final_list.csv\"\n",
    "universities_df = pd.read_csv(csv_file)\n",
    "    \n",
    " # 打印前 5 行\n",
    "print(\"\\n文件内容的前5行:\")\n",
    "print(universities_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "93d934d1-6255-4e34-89d7-01ddeceff85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool_calls Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content='', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='t-web_search-67ee83565106', function=Function(arguments='{\"search_result\":{\"search_id\":\"2e46c4ab67ee83561545630001fd8706\"},\"usage\":{\"total_tokens\":6965}}', name='$web_search'), type='builtin_function')]))\n",
      "tool_calls Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content='', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='t-web_search-67ee83581f55', function=Function(arguments='{\"search_result\":{\"search_id\":\"2504a0d567ee83582b42f60001e8312f\"},\"usage\":{\"total_tokens\":6965}}', name='$web_search'), type='builtin_function')]))\n",
      "tool_calls Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content='', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='t-web_search-67ee835ac658', function=Function(arguments='{\"search_result\":{\"search_id\":\"7edd0c0f67ee835a2b42f60001e83135\"},\"usage\":{\"total_tokens\":6965}}', name='$web_search'), type='builtin_function')]))\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Your account org-1e3a0d58c26f40d7afa4909fbeeb8229<ak-ezq8bd99ui1111ae71ki> request reached organization max RPM: 3, please try again after 1 seconds', 'type': 'rate_limit_reached_error'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[112], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m60\u001b[39m)\n\u001b[0;32m     12\u001b[0m name \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 13\u001b[0m result \u001b[38;5;241m=\u001b[39m single_search(name)  \u001b[38;5;66;03m# 调用函数\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(result, \u001b[38;5;28mtype\u001b[39m(result))\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mloads(result[\u001b[38;5;241m8\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m]))\n",
      "Cell \u001b[1;32mIn[110], line 59\u001b[0m, in \u001b[0;36msingle_search\u001b[1;34m(university_name)\u001b[0m\n\u001b[0;32m     57\u001b[0m finish_reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m finish_reason \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m finish_reason \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 59\u001b[0m     choice \u001b[38;5;241m=\u001b[39m chat(messages)\n\u001b[0;32m     60\u001b[0m     finish_reason \u001b[38;5;241m=\u001b[39m choice\u001b[38;5;241m.\u001b[39mfinish_reason\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28mprint\u001b[39m(finish_reason, choice)\n",
      "Cell \u001b[1;32mIn[110], line 30\u001b[0m, in \u001b[0;36mchat\u001b[1;34m(messages)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchat\u001b[39m(messages) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Choice:\n\u001b[1;32m---> 30\u001b[0m     completion \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     31\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmoonshot-v1-8k\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     32\u001b[0m         messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[0;32m     33\u001b[0m         temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m,\n\u001b[0;32m     34\u001b[0m         tools\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     35\u001b[0m             {\n\u001b[0;32m     36\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuiltin_function\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# <-- 使用 builtin_function 声明 $web_search 函数，请在每次请求都完整地带上 tools 声明\u001b[39;00m\n\u001b[0;32m     37\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m     38\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$web_search\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     39\u001b[0m                 },\n\u001b[0;32m     40\u001b[0m             }\n\u001b[0;32m     41\u001b[0m         ]\n\u001b[0;32m     42\u001b[0m     )\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\openai\\_utils\\_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:914\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    911\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    912\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    913\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    915\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    916\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m    917\u001b[0m             {\n\u001b[0;32m    918\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m    919\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m    920\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio,\n\u001b[0;32m    921\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m    922\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[0;32m    923\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[0;32m    924\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m    925\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m    926\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[0;32m    927\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m    928\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    929\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodalities\u001b[39m\u001b[38;5;124m\"\u001b[39m: modalities,\n\u001b[0;32m    930\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m    931\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[0;32m    932\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: prediction,\n\u001b[0;32m    933\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m    934\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_effort\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_effort,\n\u001b[0;32m    935\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m    936\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m    937\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[0;32m    938\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m    939\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[0;32m    940\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m    941\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[0;32m    942\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m    943\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m    944\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m    945\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[0;32m    946\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m    947\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m    948\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb_search_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: web_search_options,\n\u001b[0;32m    949\u001b[0m             },\n\u001b[0;32m    950\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[0;32m    951\u001b[0m         ),\n\u001b[0;32m    952\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    953\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    954\u001b[0m         ),\n\u001b[0;32m    955\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[0;32m    956\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    957\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[0;32m    958\u001b[0m     )\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\openai\\_base_client.py:1242\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1229\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1230\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1238\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1239\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1240\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1241\u001b[0m     )\n\u001b[1;32m-> 1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\openai\\_base_client.py:919\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 919\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m    920\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    921\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    922\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    923\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    924\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m    925\u001b[0m )\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\openai\\_base_client.py:1008\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1007\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1008\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[0;32m   1009\u001b[0m         input_options,\n\u001b[0;32m   1010\u001b[0m         cast_to,\n\u001b[0;32m   1011\u001b[0m         retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1012\u001b[0m         response_headers\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m   1013\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1014\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1018\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\openai\\_base_client.py:1057\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m   1058\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1059\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1060\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1061\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1062\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1063\u001b[0m )\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\openai\\_base_client.py:1008\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1007\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1008\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[0;32m   1009\u001b[0m         input_options,\n\u001b[0;32m   1010\u001b[0m         cast_to,\n\u001b[0;32m   1011\u001b[0m         retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1012\u001b[0m         response_headers\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m   1013\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1014\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1018\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\openai\\_base_client.py:1057\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m   1058\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1059\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1060\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1061\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1062\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1063\u001b[0m )\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\openai\\_base_client.py:1023\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1020\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1022\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1026\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1027\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1031\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1032\u001b[0m )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'Your account org-1e3a0d58c26f40d7afa4909fbeeb8229<ak-ezq8bd99ui1111ae71ki> request reached organization max RPM: 3, please try again after 1 seconds', 'type': 'rate_limit_reached_error'}}"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "# 创建一个新的 DataFrame 用于存储结果\n",
    "new_df = pd.DataFrame()\n",
    "\n",
    "# 遍历每一行，提取 'name' 字段\n",
    "for index, row in universities_df.iterrows():\n",
    "    if index == 2:\n",
    "        break\n",
    "    time.sleep(60)\n",
    "    name = row['name']\n",
    "    result = single_search(name)  # 调用函数\n",
    "    print(result, type(result))\n",
    "    print(json.loads(result[8:-3]))\n",
    "    # 将返回的 JSON 列表转换为 DataFrame 并拼接到 new_df\n",
    "    result_df = pd.DataFrame(json.loads(result[8:-3]))\n",
    "    new_df = pd.concat([new_df, result_df], ignore_index=True)\n",
    "\n",
    "# 打印新 DataFrame 的前 5 行\n",
    "print(\"\\n新 DataFrame 的前5行:\")\n",
    "print(new_df.head())\n",
    " \n",
    "# 将新 DataFrame 保存为新的 CSV 文件\n",
    "new_csv_file = \"processed_results.csv\"\n",
    "new_df.to_csv(new_csv_file, index=False)\n",
    "print(f\"\\n新 CSV 文件已生成: {new_csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b46ee91-445d-46f4-a045-74b435899331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
